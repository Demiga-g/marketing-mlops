{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.16\n"
     ]
    }
   ],
   "source": [
    "# Checking Python's version\n",
    "!python -V"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import pickle\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from hyperopt.pyll import scope\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, space_eval\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import (f1_score,\n",
    "                             recall_score,\n",
    "                             roc_auc_score,\n",
    "                             accuracy_score, \n",
    "                             precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read training and validation data\n",
    "df_train = pd.read_csv('./data/training_data.csv')\n",
    "df_val = pd.read_csv('./data/validation_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating target variable \n",
    "y_train = df_train['Response']\n",
    "y_val = df_val['Response']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the necessary variables\n",
    "dependants = ['Kidhome', 'Teenhome']\n",
    "\n",
    "# assuming analysis was conducted in 2014 \n",
    "now = 2014\n",
    "\n",
    "# Define the bin edges\n",
    "bins = [18, 28, 38, 48, 58, 65, np.inf]\n",
    "\n",
    "# Define the labels for each age group\n",
    "labels = ['18-27', '28-37', '38-47', '48-57', '58-65', '65+']\n",
    "\n",
    "# End of financial year\n",
    "end_fiscal = datetime(2014, 6, 30)\n",
    "\n",
    "# Redundant features\n",
    "red_ftrs_1 = [\"ID\", \"Year_Birth\", \"Dt_Customer\", \"Z_CostContact\", \"Z_Revenue\", \"Response\",'Age']\n",
    "\n",
    "# List of categorical and numeric features\n",
    "categ_ftrs_1 = ['Education', 'Marital_Status', 'Kidhome', 'Teenhome', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1', 'AcceptedCmp2', 'Complain', 'Age_Group']\n",
    "\n",
    "num_ftrs_1 = ['Income', 'Recency', 'MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth', 'Onboard_Days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to do data cleaning and feature preprocessing\n",
    "def scrub_data(df):\n",
    "    \n",
    "    # Convert 'Kidhome' and 'Teenhome' to categorical\n",
    "    # but first fillna with the most frequent value\n",
    "    df[dependants] = df[dependants].fillna(df[dependants].mode().iloc[0])\n",
    "    df[dependants] = df[dependants].applymap(lambda x: 1 if x > 0 else 0)\n",
    "    \n",
    "    # Conversions into 'datetime' data type\n",
    "    # but first fillna in both variables\n",
    "    df['Year_Birth'] = df['Year_Birth'].fillna(int(df['Year_Birth'].median()))\n",
    "    df['Year_Birth'] = pd.to_datetime(df['Year_Birth'], format='%Y')\n",
    "    \n",
    "    df['Dt_Customer'] = df['Dt_Customer'].fillna(df['Dt_Customer'].mode().iloc[0])\n",
    "    df[\"Dt_Customer\"] = pd.to_datetime(df[\"Dt_Customer\"])\n",
    "    \n",
    "    # Calculate age\n",
    "    df['Age'] = now - df['Year_Birth'].dt.year\n",
    "    \n",
    "    # Create age group feature\n",
    "    df['Age_Group'] = pd.cut(df['Age'], bins=bins, labels=labels, right=False)\n",
    "    \n",
    "    # Calculate the number of days since customer enrolled\n",
    "    df['Onboard_Days'] = (end_fiscal - df['Dt_Customer']).dt.days\n",
    "    \n",
    "    # Droping redundant features\n",
    "    df = df.drop(red_ftrs_1, axis=1)\n",
    "    \n",
    "    # handle missing values and scale numeric data\n",
    "    num_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('normalize', PowerTransformer(method='yeo-johnson')),\n",
    "    ])\n",
    "    \n",
    "    ct = ColumnTransformer([\n",
    "        ('num_trans', num_transformer, num_ftrs_1),\n",
    "        ('cat_trans', SimpleImputer(strategy='most_frequent'), categ_ftrs_1)\n",
    "    ])\n",
    "        \n",
    "    df = pd.DataFrame(ct.fit_transform(df), \n",
    "                      columns=num_ftrs_1+categ_ftrs_1)\n",
    "    \n",
    "    # Ensure that the final df features are in the right data types\n",
    "    df[categ_ftrs_1] = df[categ_ftrs_1].astype('str')\n",
    "    df[num_ftrs_1] = df[num_ftrs_1].astype('float')\n",
    "     \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and preprocess the data ones\n",
    "train_data = scrub_data(df_train)\n",
    "val_data = scrub_data(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From DataFrame to dictionary\n",
    "train_dicts= train_data.to_dict(orient='records')\n",
    "val_dicts = val_data.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use dictionary vectorizer\n",
    "dv = DictVectorizer()\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "X_val = dv.transform(val_dicts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing for MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting tracking uri\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics_logs(y_true, y_pred):\n",
    "    # Calculate the evaluation metrics\n",
    "    f1 = f1_score(y_val, y_pred.round())\n",
    "    precision = precision_score(y_val, y_pred.round(), zero_division=0)\n",
    "    recall = recall_score(y_val, y_pred.round())\n",
    "    pr_auc = roc_auc_score(y_val, y_pred.round())\n",
    "    accuracy = accuracy_score(y_val, y_pred.round())\n",
    "    \n",
    "    # Log the evaluation metrics\n",
    "    mlflow.log_metric(\"f1\", f1)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"pr_auc\", pr_auc)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy) \n",
    "    \n",
    "    return precision"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking which Classifiers to Focus on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/18 08:17:57 INFO mlflow.tracking.fluent: Experiment with name 'all-models-experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/home/mgubuntu/projects/marketing-mlops/02-experiment-tracking/mlruns/1', creation_time=1687065477952, experiment_id='1', last_update_time=1687065477952, lifecycle_stage='active', name='all-models-experiment', tags={}>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting experiment\n",
    "mlflow.set_experiment('all-models-experiment')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/18 08:18:48 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/mgubuntu/anaconda3/envs/marketing_MLOps/lib/python3.9/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n",
      "/home/mgubuntu/anaconda3/envs/marketing_MLOps/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "mlflow.sklearn.autolog()\n",
    "\n",
    "for model_class in (SVC, \n",
    "                    LogisticRegression,\n",
    "                    RandomForestClassifier, \n",
    "                    GradientBoostingClassifier\n",
    "):\n",
    "\n",
    "    with mlflow.start_run():\n",
    "\n",
    "        mlmodel = model_class()\n",
    "        mlmodel.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = mlmodel.predict(X_val)\n",
    "        \n",
    "        eval_metrics_logs(y_val, y_pred.round())\n",
    "        \n",
    "mlflow.sklearn.autolog(disable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = xgb.DMatrix(X_train, label=y_train)\n",
    "valid = xgb.DMatrix(X_val, label=y_val)\n",
    "_params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': \"logloss\",\n",
    "    'seed': 42,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/18 08:19:53 WARNING mlflow.xgboost: Failed to infer model signature: could not sample data to infer model signature: please ensure that autologging is enabled before constructing the dataset.\n"
     ]
    }
   ],
   "source": [
    "mlflow.xgboost.autolog()\n",
    "\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    mlflow.log_params(_params)\n",
    "    \n",
    "    booster = xgb.train(\n",
    "        params=_params,\n",
    "        dtrain=train,\n",
    "        num_boost_round=500,\n",
    "        evals=[(valid, \"validation\")],\n",
    "        early_stopping_rounds=250, \n",
    "        verbose_eval=False\n",
    "    )\n",
    "    y_pred = booster.predict(valid)\n",
    "    \n",
    "    eval_metrics_logs(y_val, y_pred.round())\n",
    "    \n",
    "mlflow.xgboost.autolog(disable=True)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/18 08:19:56 INFO mlflow.tracking.fluent: Experiment with name 'rfc-experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/home/mgubuntu/projects/marketing-mlops/02-experiment-tracking/mlruns/2', creation_time=1687065596730, experiment_id='2', last_update_time=1687065596730, lifecycle_stage='active', name='rfc-experiment', tags={}>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment('rfc-experiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a random state \n",
    "random_state = np.random.default_rng(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the objective function\n",
    "def objective(params):\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        model = RandomForestClassifier(**params, n_jobs=-1, \n",
    "                                       random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_val)\n",
    "        \n",
    "        precision = eval_metrics_logs(y_val, y_pred.round())\n",
    "        \n",
    "    return {'loss': -precision, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definining the hyperparameters\n",
    "search_space = {\n",
    "    'n_estimators': scope.int(hp.quniform('n_estimators', 10, 150, 10)),\n",
    "    'criterion': hp.choice('criterion', ['gini', 'entropy']),\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 10, 30, 10)),   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = fmin(\n",
    "    fn=objective,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=30,\n",
    "    rstate=random_state,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/18 08:21:01 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '81b07afc8a014cebb3c98a0b22f77acc', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    }
   ],
   "source": [
    "params = {'criterion': 'entropy', \n",
    "          'max_depth': 20, \n",
    "          'n_estimators': 60}\n",
    "\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "rfc = RandomForestClassifier(**params, n_jobs=-1, \n",
    "                             random_state=42)\n",
    "rfc.fit(X_train, y_train)      \n",
    "\n",
    "mlflow.sklearn.autolog(disable=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sci-Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/18 08:21:12 INFO mlflow.tracking.fluent: Experiment with name 'sk-gbc-experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/home/mgubuntu/projects/marketing-mlops/02-experiment-tracking/mlruns/3', creation_time=1687065672903, experiment_id='3', last_update_time=1687065672903, lifecycle_stage='active', name='sk-gbc-experiment', tags={}>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment('sk-gbc-experiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        model = GradientBoostingClassifier(**params, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        \n",
    "        precision = eval_metrics_logs(y_val, y_pred.round())\n",
    "        \n",
    "        return {'loss': -precision, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'n_estimators': scope.int(hp.quniform('n_estimators', 50, 100, 10)),\n",
    "    'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 16, 2)), \n",
    "    'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 10, 1)), \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = fmin(\n",
    "    fn = objective,\n",
    "    space = search_space,\n",
    "    algo = tpe.suggest,\n",
    "    max_evals = 30,\n",
    "    trials = Trials(),\n",
    "    rstate=random_state,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/18 08:22:32 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '833fedd2ce1d4178a17173201807c668', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    }
   ],
   "source": [
    "params = {'min_samples_leaf': 8,\n",
    "'min_samples_split': 14,\n",
    "'n_estimators': 90}\n",
    "\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "gbc = GradientBoostingClassifier(**params, random_state=42)\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "mlflow.sklearn.autolog(disable=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X-Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/18 08:22:44 INFO mlflow.tracking.fluent: Experiment with name 'xgbc-experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/home/mgubuntu/projects/marketing-mlops/02-experiment-tracking/mlruns/4', creation_time=1687065764674, experiment_id='4', last_update_time=1687065764674, lifecycle_stage='active', name='xgbc-experiment', tags={}>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment('xgbc-experiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the objective function\n",
    "def objective(params):\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_params(params)\n",
    "        model = xgb.XGBClassifier(**params, \n",
    "                                  random_state=42, \n",
    "                                  objective='binary:logistic')\n",
    "        model.set_params(early_stopping_rounds=250)\n",
    "        model.fit(X_train, y_train, \n",
    "                  eval_set=[(X_val, y_val)],\n",
    "                  verbose=False)\n",
    "        y_pred = model.predict(X_val)\n",
    "        \n",
    "        precision = eval_metrics_logs(y_val, y_pred.round())\n",
    "        \n",
    "    return {'loss': -precision, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'n_estimators': scope.int(hp.quniform('n_estimators', 50, 80, 10)),\n",
    "    'max_leaves': scope.int(hp.quniform('max_leaves', 1, 100, 10)),\n",
    "    'min_child_weight': hp.loguniform('min_child_weight', 1.5, 2.5),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = fmin(\n",
    "    fn = objective,\n",
    "    space = search_space,\n",
    "    algo = tpe.suggest,\n",
    "    max_evals = 30,\n",
    "    trials = Trials(),\n",
    "    rstate=random_state,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/18 08:24:56 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'd0949320564b43239c5dac3831c4b665', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current xgboost workflow\n"
     ]
    }
   ],
   "source": [
    "params = {'max_leaves':\t50, \n",
    "'min_child_weight':\t7.727056599504389, \n",
    "'n_estimators':\t50}\n",
    "\n",
    "mlflow.xgboost.autolog()\n",
    "\n",
    "xgbc = xgb.XGBClassifier(**params, \n",
    "                          random_state=42, \n",
    "                          objective='binary:logistic')\n",
    "xgbc.set_params(early_stopping_rounds=250)\n",
    "xgbc.fit(X_train, y_train,  eval_set=[(X_val, y_val)], verbose=False)\n",
    "\n",
    "mlflow.xgboost.autolog(disable=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/18 08:25:06 INFO mlflow.tracking.fluent: Experiment with name 'svc-experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/home/mgubuntu/projects/marketing-mlops/02-experiment-tracking/mlruns/5', creation_time=1687065906686, experiment_id='5', last_update_time=1687065906686, lifecycle_stage='active', name='svc-experiment', tags={}>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment('svc-experiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        model = SVC(**params, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        \n",
    "        precision = eval_metrics_logs(y_val, y_pred.round())\n",
    "        \n",
    "    return {'loss': -precision, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'C': hp.uniform('C', 0, 10),\n",
    "    # 'kernel': hp.choice('kernel', ['poly', 'rbf', 'sigmoid']), \n",
    "    'degree': scope.int(hp.randint('degree', 1, 12)),\n",
    "    # 'gamma': hp.choice('gamma', ['scale', 'auto']),\n",
    "    # 'class_weight': hp.choice('class_weight', [None, 'balanced'])   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = fmin(\n",
    "    fn=objective,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=30,\n",
    "    rstate=random_state,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/18 08:25:41 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '758d276c6d2d414ab0b81e73565d04fe', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'C': 2.521616767609426,\n",
    "    'degree': 2\n",
    "}\n",
    "\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "svc = SVC(**params, random_state=42)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "mlflow.sklearn.autolog(disable=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/18 08:25:56 INFO mlflow.tracking.fluent: Experiment with name 'xgboost-experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/home/mgubuntu/projects/marketing-mlops/02-experiment-tracking/mlruns/6', creation_time=1687065956014, experiment_id='6', last_update_time=1687065956014, lifecycle_stage='active', name='xgboost-experiment', tags={}>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"xgboost-experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag(\"model\", \"xgboost\")\n",
    "        mlflow.log_params(params)\n",
    "        booster = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=train,\n",
    "            num_boost_round=500,\n",
    "            evals=[(valid, \"validation\")],\n",
    "            early_stopping_rounds=250, \n",
    "            verbose_eval=False\n",
    "        )\n",
    "        y_pred = booster.predict(valid)\n",
    "        \n",
    "        precision = eval_metrics_logs(y_val, y_pred.round())\n",
    "        \n",
    "    return {'loss': -precision, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 20, 70, 10)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -30, -3),\n",
    "    'min_child_weight': hp.loguniform('min_child_weight', 1.5, 2.5),\n",
    "    # 'scale_pos_weight': hp.uniform('scale_pos_weight', 1, 10),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1),\n",
    "    # 'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n",
    "    # 'gamma': hp.uniform('gamma', 0, 1),\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': \"logloss\",\n",
    "    'seed': 42,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [04:53<00:00,  9.80s/trial, best loss: -0.5737704918032787]\n"
     ]
    }
   ],
   "source": [
    "best_result = fmin(\n",
    "    fn = objective,\n",
    "    space = search_space,\n",
    "    algo = tpe.suggest,\n",
    "    max_evals = 30,\n",
    "    trials = Trials(),\n",
    "    rstate=random_state,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/18 08:30:50 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'be5e5f514cd347e1876e2a9404a8a8ea', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current xgboost workflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/18 08:30:55 WARNING mlflow.xgboost: Failed to infer model signature: could not sample data to infer model signature: please ensure that autologging is enabled before constructing the dataset.\n"
     ]
    }
   ],
   "source": [
    "# params = space_eval(search_space, best_result)\n",
    "params = {\n",
    "    'eval_metric':'logloss',\n",
    "    'gamma':0.9511548717715149,\n",
    "    'learning_rate':0.014685011379954318,\n",
    "    'max_depth':149,\n",
    "    'min_child_weight':7.668601934406394,\n",
    "    'objective':'binary:logistic',\n",
    "    'seed':\t42,\n",
    "    'subsample':0.51735171792841\n",
    "}\n",
    "\n",
    "mlflow.xgboost.autolog()\n",
    "\n",
    "booster = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=train,\n",
    "    num_boost_round=500,\n",
    "    evals=[(valid, \"validation\")],\n",
    "    early_stopping_rounds=20,\n",
    "    verbose_eval=False\n",
    ")\n",
    "\n",
    "mlflow.xgboost.autolog(disable=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/18 08:30:58 INFO mlflow.tracking.fluent: Experiment with name 'log-reg-experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/home/mgubuntu/projects/marketing-mlops/02-experiment-tracking/mlruns/7', creation_time=1687066258720, experiment_id='7', last_update_time=1687066258720, lifecycle_stage='active', name='log-reg-experiment', tags={}>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"log-reg-experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'C': hp.loguniform('C', -20, 4),\n",
    "    'class_weight': hp.choice('class_weight', [None, 'balanced']),\n",
    "    'penalty': hp.choice('penalty', ['l1', 'l2']),\n",
    "    'solver': hp.choice('solver', ['liblinear', 'saga'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_params(params)\n",
    "    \n",
    "        # Create the logistic regression model with the given hyperparameters\n",
    "        model = LogisticRegression(**params, max_iter=5000)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        \n",
    "        precision = eval_metrics_logs(y_val, y_pred.round())\n",
    "    \n",
    "    return {'loss': -precision, 'status': STATUS_OK}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = fmin(\n",
    "    fn = objective,\n",
    "    space = space,\n",
    "    algo = tpe.suggest,\n",
    "    max_evals = 100,\n",
    "    trials = Trials(),\n",
    "    rstate=random_state,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/18 08:33:05 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '29f060aa0ba04c1a8b560765b3a31414', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    }
   ],
   "source": [
    "#Best parameters\n",
    "params = {'C': 0.08966267017951414, \n",
    "          'class_weight': None,\n",
    "          'penalty': 'l1',\n",
    "          'solver':\t'liblinear'\n",
    "}\n",
    "\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "lr = LogisticRegression(**params, max_iter=5000)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "mlflow.sklearn.autolog(disable=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marketing_MLOps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
