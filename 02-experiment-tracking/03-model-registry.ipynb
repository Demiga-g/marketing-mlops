{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Client Class\n",
    "from mlflow.tracking import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLFLOW_TRACKING_URI = \"sqlite:///mlflow.db\" \n",
    "\n",
    "# Instantiate the Client object\n",
    "client = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run id: f1dd542d7cf04b85ac01b35b016e25df,        precision: 0.5373,        recall: 0.7500\n",
      "run id: 7d5b48a8fe764b5a8e397dd3c8c96c7d,        precision: 0.5333,        recall: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Check best runs in experiment id 1 (all models)\n",
    "from mlflow.entities import ViewType\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=1,\n",
    "    filter_string='metrics.precision > 0.523',\n",
    "    run_view_type=ViewType.ACTIVE_ONLY,\n",
    "    max_results=7,\n",
    "    order_by=['metrics.precision DESC']\n",
    ")\n",
    "\n",
    "for run in runs:\n",
    "    print(f\"run id: {run.info.run_id},\\\n",
    "        precision: {run.data.metrics['precision']:.4f},\\\n",
    "        recall: {run.data.metrics['recall']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Promoting models to model registry\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Register the default Random Forest Classifier\n",
    "register_name = 'marketing-campaign-classifier'\n",
    "\n",
    "rfc_log_model = 'runs:/5c2a48899a884f0498d6bac2468626b5/model'\n",
    "client.create_model_version(\n",
    "    name=register_name,\n",
    "    source=\"mlruns/1/5c2a48899a884f0498d6bac2468626b5/artifacts/model\", \n",
    "    run_id=rfc_log_model,\n",
    "    description=f\"Default Random Forest Classifier\",\n",
    ")\n",
    "\n",
    "#Transition it to staging\n",
    "client.transition_model_version_stage(\n",
    "    name=register_name,\n",
    "    version=2,\n",
    "    stage=\"staging\",\n",
    "    archive_existing_versions=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Register the GradientBoosting Classifier (best model)\n",
    "gbc_log_model = 'runs:/7671c657fe944c469938a59945f06d53/model'\n",
    "client.create_model_version(\n",
    "    name=register_name,\n",
    "    source=\"mlruns/8/7671c657fe944c469938a59945f06d53/artifacts/model\", \n",
    "    run_id=gbc_log_model,\n",
    "    description=f\"Gradient Boosting Classifier turned out to be the 'best' model\",\n",
    ")\n",
    "#Transition it to production\n",
    "client.transition_model_version_stage(\n",
    "    name=register_name,\n",
    "    version=3,\n",
    "    stage=\"production\",\n",
    "    archive_existing_versions=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version: 8, stage: Archived\n",
      "version: 2, stage: Production\n",
      "version: 9, stage: Staging\n"
     ]
    }
   ],
   "source": [
    "#Check the list of latest model versions\n",
    "register_name = 'marketing-campaign-classifier'\n",
    "latest_versions = client.get_latest_versions(name=register_name)\n",
    "for version in latest_versions:\n",
    "    print(f\"version: {version.version}, stage: {version.current_stage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See which model to promote "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import (f1_score,\n",
    "                             recall_score,\n",
    "                             roc_auc_score,\n",
    "                             accuracy_score, \n",
    "                             precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the necessary variables\n",
    "dependants = ['Kidhome', 'Teenhome']\n",
    "\n",
    "# assuming analysis was conducted in 2014 \n",
    "now = 2014\n",
    "\n",
    "# Define the bin edges\n",
    "bins = [18, 28, 38, 48, 58, 65, np.inf]\n",
    "\n",
    "# Define the labels for each age group\n",
    "labels = ['18-27', '28-37', '38-47', '48-57', '58-65', '65+']\n",
    "\n",
    "# End of financial year\n",
    "end_fiscal = datetime(2014, 6, 30)\n",
    "\n",
    "# Redundant features\n",
    "red_ftrs_1 = [\"ID\", \"Year_Birth\", \"Dt_Customer\", \"Z_CostContact\", \"Z_Revenue\", \"Response\",'Age']\n",
    "\n",
    "# List of categorical and numeric features\n",
    "categ_ftrs_1 = ['Education', 'Marital_Status', 'Kidhome', 'Teenhome', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1', 'AcceptedCmp2', 'Complain', 'Age_Group']\n",
    "\n",
    "num_ftrs_1 = ['Income', 'Recency', 'MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth', 'Onboard_Days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to do data cleaning and feature preprocessing\n",
    "def scrub_data(filename):\n",
    "    \n",
    "    df = pd.read_csv(filename)\n",
    "    y_data = df['Response']\n",
    "    \n",
    "    # Convert 'Kidhome' and 'Teenhome' to categorical\n",
    "    # but first fillna with the most frequent value\n",
    "    df[dependants] = df[dependants].fillna(df[dependants].mode().iloc[0])\n",
    "    df[dependants] = df[dependants].applymap(lambda x: 1 if x > 0 else 0)\n",
    "    \n",
    "    # Conversions into 'datetime' data type\n",
    "    # but first fillna in both variables\n",
    "    df['Year_Birth'] = df['Year_Birth'].fillna(int(df['Year_Birth'].median()))\n",
    "    df['Year_Birth'] = pd.to_datetime(df['Year_Birth'], format='%Y')\n",
    "    \n",
    "    df['Dt_Customer'] = df['Dt_Customer'].fillna(df['Dt_Customer'].mode().iloc[0])\n",
    "    df[\"Dt_Customer\"] = pd.to_datetime(df[\"Dt_Customer\"])\n",
    "    \n",
    "    # Calculate age\n",
    "    df['Age'] = now - df['Year_Birth'].dt.year\n",
    "    \n",
    "    # Create age group feature\n",
    "    df['Age_Group'] = pd.cut(df['Age'], bins=bins, labels=labels, right=False)\n",
    "    \n",
    "    # Calculate the number of days since customer enrolled\n",
    "    df['Onboard_Days'] = (end_fiscal - df['Dt_Customer']).dt.days\n",
    "    \n",
    "    # Droping redundant features\n",
    "    df = df.drop(red_ftrs_1, axis=1)\n",
    "    \n",
    "    # handle missing values and scale numeric data\n",
    "    ct = ColumnTransformer([\n",
    "        ('num_trans', SimpleImputer(strategy='median'), num_ftrs_1),\n",
    "        ('cat_trans', SimpleImputer(strategy='most_frequent'), categ_ftrs_1)\n",
    "    ])\n",
    "        \n",
    "    df = pd.DataFrame(ct.fit_transform(df), \n",
    "                      columns=num_ftrs_1+categ_ftrs_1)\n",
    "    \n",
    "    # Ensure that the final df features are in the right data types\n",
    "    df[categ_ftrs_1] = df[categ_ftrs_1].astype('str')\n",
    "    df[num_ftrs_1] = df[num_ftrs_1].astype('float')\n",
    "     \n",
    "    return (df, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data, y_data = scrub_data(\"./data/synthetic-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to vectorize the data\n",
    "def preprocess(df, dv):\n",
    "    df_dicts= df.to_dict(orient='records')\n",
    "    return dv.transform(df_dicts)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models/preprocessor.b\", \"rb\") as f_in:\n",
    "    dv = pickle.load(f_in)\n",
    "    \n",
    "X_data = preprocess(X_data, dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(name, X_data, y_data, stage):\n",
    "    model = mlflow.pyfunc.load_model(f\"models:/{name}/{stage}\")\n",
    "    y_pred = model.predict(X_data)\n",
    "    precision = precision_score(y_data, y_pred.round(), zero_division=0)\n",
    "    recall = recall_score(y_data, y_pred.round())\n",
    "    return {f\"precision: {precision}, recall: {recall}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/30 10:03:42 WARNING mlflow.pyfunc: Detected one or more mismatches between the model's dependencies and the current Python environment:\n",
      " - mlflow (current: 2.3.2, required: mlflow==2.3)\n",
      "To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 807 ms, sys: 40.1 ms, total: 847 ms\n",
      "Wall time: 852 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision: 0.44587458745874586, recall: 0.9996300406955235'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "test_model(name=register_name, stage=\"Staging\", \n",
    "           X_data=X_data, y_data=y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transition it to production\n",
    "client.transition_model_version_stage(\n",
    "    name=register_name,\n",
    "    version=2,\n",
    "    stage=\"production\",\n",
    "    archive_existing_versions=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marketing_MLOps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
