{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import (f1_score,\n",
    "                             recall_score,\n",
    "                             roc_auc_score,\n",
    "                             accuracy_score, \n",
    "                             precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read training and validation data\n",
    "df_train = pd.read_csv('./data/training_data.csv')\n",
    "df_val = pd.read_csv('./data/validation_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating target variable \n",
    "y_train = df_train['Response']\n",
    "y_val = df_val['Response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the necessary variables\n",
    "dependants = ['Kidhome', 'Teenhome']\n",
    "\n",
    "# assuming analysis was conducted in 2014 \n",
    "now = 2014\n",
    "\n",
    "# Define the bin edges\n",
    "bins = [18, 28, 38, 48, 58, 65, np.inf]\n",
    "\n",
    "# Define the labels for each age group\n",
    "labels = ['18-27', '28-37', '38-47', '48-57', '58-65', '65+']\n",
    "\n",
    "# End of financial year\n",
    "end_fiscal = datetime(2014, 6, 30)\n",
    "\n",
    "# Redundant features\n",
    "red_ftrs_1 = [\"ID\", \"Year_Birth\", \"Dt_Customer\", \"Z_CostContact\", \"Z_Revenue\", \"Response\",'Age']\n",
    "\n",
    "# List of categorical and numeric features\n",
    "categ_ftrs_1 = ['Education', 'Marital_Status', 'Kidhome', 'Teenhome', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1', 'AcceptedCmp2', 'Complain', 'Age_Group']\n",
    "\n",
    "num_ftrs_1 = ['Income', 'Recency', 'MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth', 'Onboard_Days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to do data cleaning and feature preprocessing\n",
    "def scrub_data(df):\n",
    "    \n",
    "    # Convert 'Kidhome' and 'Teenhome' to categorical\n",
    "    # but first fillna with the most frequent value\n",
    "    df[dependants] = df[dependants].fillna(df[dependants].mode().iloc[0])\n",
    "    df[dependants] = df[dependants].applymap(lambda x: 1 if x > 0 else 0)\n",
    "    \n",
    "    # Conversions into 'datetime' data type\n",
    "    # but first fillna in both variables\n",
    "    df['Year_Birth'] = df['Year_Birth'].fillna(int(df['Year_Birth'].median()))\n",
    "    df['Year_Birth'] = pd.to_datetime(df['Year_Birth'], format='%Y')\n",
    "    \n",
    "    df['Dt_Customer'] = df['Dt_Customer'].fillna(df['Dt_Customer'].mode().iloc[0])\n",
    "    df[\"Dt_Customer\"] = pd.to_datetime(df[\"Dt_Customer\"])\n",
    "    \n",
    "    # Calculate age\n",
    "    df['Age'] = now - df['Year_Birth'].dt.year\n",
    "    \n",
    "    # Create age group feature\n",
    "    df['Age_Group'] = pd.cut(df['Age'], bins=bins, labels=labels, right=False)\n",
    "    \n",
    "    # Calculate the number of days since customer enrolled\n",
    "    df['Onboard_Days'] = (end_fiscal - df['Dt_Customer']).dt.days\n",
    "    \n",
    "    # Droping redundant features\n",
    "    df = df.drop(red_ftrs_1, axis=1)\n",
    "    \n",
    "    # handle missing values and scale numeric data\n",
    "    num_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('normalize', PowerTransformer(method='yeo-johnson')),\n",
    "    ])\n",
    "    \n",
    "    ct = ColumnTransformer([\n",
    "        ('num_trans', num_transformer, num_ftrs_1),\n",
    "        ('cat_trans', SimpleImputer(strategy='most_frequent'), categ_ftrs_1)\n",
    "    ])\n",
    "        \n",
    "    df = pd.DataFrame(ct.fit_transform(df), \n",
    "                      columns=num_ftrs_1+categ_ftrs_1)\n",
    "    \n",
    "    # Ensure that the final df features are in the right data types\n",
    "    df[categ_ftrs_1] = df[categ_ftrs_1].astype('str')\n",
    "    df[num_ftrs_1] = df[num_ftrs_1].astype('float')\n",
    "     \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and preprocess the data ones\n",
    "train_data = scrub_data(df_train)\n",
    "val_data = scrub_data(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From DataFrame to dictionary\n",
    "train_dicts= train_data.to_dict(orient='records')\n",
    "val_dicts = val_data.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use dictionary vectorizer\n",
    "dv = DictVectorizer()\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "X_val = dv.transform(val_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the preprocessor\n",
    "with open('models/preprocessor.b', 'wb') as f_out:\n",
    "    pickle.dump(dv, f_out)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/29 23:58:36 INFO mlflow.tracking.fluent: Experiment with name 'best_model' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/home/mgubuntu/projects/marketing-mlops/02-experiment-tracking/mlruns/8', creation_time=1688072316687, experiment_id='8', last_update_time=1688072316687, lifecycle_stage='active', name='best_model', tags={}>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set tracking uri\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "\n",
    "# Set experiment\n",
    "mlflow.set_experiment('best_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mgubuntu/anaconda3/envs/marketing_MLOps/lib/python3.9/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "# Train the best model and log it in mlflow\n",
    "with mlflow.start_run():\n",
    "    params = {\n",
    "        'min_samples_leaf': 8, \n",
    "        'min_samples_split': 14, \n",
    "        'n_estimators': 90\n",
    "    }\n",
    "    \n",
    "    # Log the parameters\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    gbc = GradientBoostingClassifier(**params, random_state=42)\n",
    "    gbc.fit(X_train, y_train)\n",
    "    y_pred = gbc.predict(X_val)\n",
    "    \n",
    "    # Calculate the evaluation metrics\n",
    "    metrics = {\n",
    "        'f1': f1_score(y_val, y_pred.round()), \n",
    "        'precision': precision_score(y_val, y_pred.round(), zero_division=0),\n",
    "        'recall': recall_score(y_val, y_pred.round()),\n",
    "        'pr_auc': roc_auc_score(y_val, y_pred.round()),\n",
    "        'accuracy': accuracy_score(y_val, y_pred.round())\n",
    "    }\n",
    "    \n",
    "    # Log the evaluation metrics\n",
    "    mlflow.log_metrics(metrics)\n",
    "    \n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(gbc, artifact_path='model')\n",
    "   \n",
    "    # Log the preprocessor\n",
    "    mlflow.log_artifact('models/preprocessor.b', artifact_path='preprocessor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model (optional)\n",
    "with open('models/gbc.bin', 'wb') as f_out:\n",
    "    pickle.dump((dv, gbc), f_out)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/29 23:58:58 WARNING mlflow.pyfunc: Detected one or more mismatches between the model's dependencies and the current Python environment:\n",
      " - mlflow (current: 2.3.2, required: mlflow==2.3)\n",
      "To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mlflow.pyfunc.loaded_model:\n",
       "  artifact_path: model\n",
       "  flavor: mlflow.sklearn\n",
       "  run_id: f48605f827ab4ba79d0e102fadaf5897"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model run id (model uri)\n",
    "logged_model = 'runs:/f48605f827ab4ba79d0e102fadaf5897/model'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(min_samples_leaf=8, min_samples_split=14,\n",
       "                           n_estimators=90, random_state=42)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log model as a scikit-learn model\n",
    "gbc_model = mlflow.sklearn.load_model(model_uri=logged_model)\n",
    "gbc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gbc_model.predict(X_val)\n",
    "y_pred[-10:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marketing_MLOps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
