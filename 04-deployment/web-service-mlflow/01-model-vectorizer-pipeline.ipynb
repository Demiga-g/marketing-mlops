{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.16\n"
     ]
    }
   ],
   "source": [
    "# Checking Python's version\n",
    "!python -V"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import mlflow\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import (f1_score,\n",
    "                             recall_score,\n",
    "                             roc_auc_score,\n",
    "                             accuracy_score, \n",
    "                             precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/home/mgubuntu/projects/marketing-mlops/04-deployment/web-service-mlflow/artifacts_local/1', creation_time=1691053345395, experiment_id='1', last_update_time=1691053345395, lifecycle_stage='active', name='model-vectorizer-as-one', tags={}>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"model-vectorizer-as-one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_clean_data(filename: str) -> pd.DataFrame:\n",
    "    \n",
    "    \"\"\"Read in & clean the data\"\"\"\n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    # Convert 'Kidhome' and 'Teenhome' to categorical\n",
    "    # but first fillna with the most frequent value\n",
    "    dependants = ['Kidhome', 'Teenhome']\n",
    "    df[dependants] = df[dependants].fillna(df[dependants].mode().iloc[0])\n",
    "    df[dependants] = df[dependants].applymap(lambda x: 1 if x > 0 else 0)\n",
    "    \n",
    "    # Conversions into 'datetime' data type\n",
    "    # but first fillna in both variables\n",
    "    df['Year_Birth'] = df['Year_Birth'].fillna(int(df['Year_Birth'].median()))\n",
    "    df['Year_Birth'] = pd.to_datetime(df['Year_Birth'], format='%Y')\n",
    "    \n",
    "    df['Dt_Customer'] = df['Dt_Customer'].fillna(df['Dt_Customer'].mode().iloc[0])\n",
    "    df[\"Dt_Customer\"] = pd.to_datetime(df[\"Dt_Customer\"])\n",
    "    \n",
    "    # Calculate age\n",
    "    # assuming analysis was conducted in 2014 \n",
    "    now = 2014\n",
    "    df['Age'] = now - df['Year_Birth'].dt.year\n",
    "    \n",
    "    # Define the bin edges\n",
    "    bins = [18, 28, 38, 48, 58, 65, np.inf]\n",
    "    # Define the labels for each age group\n",
    "    labels = ['18-27', '28-37', '38-47', '48-57', '58-65', '65+']\n",
    "    # Create age group feature\n",
    "    df['Age_Group'] = pd.cut(df['Age'], bins=bins, labels=labels, right=False)\n",
    "    \n",
    "    # Calculate the number of days since customer enrolled\n",
    "    end_fiscal = datetime(2014, 6, 30)\n",
    "    df['Onboard_Days'] = (end_fiscal - df['Dt_Customer']).dt.days\n",
    "    \n",
    "    # Droping redundant features\n",
    "    red_ftrs_1 = [\"ID\", \"Year_Birth\", \"Dt_Customer\", \"Z_CostContact\", \"Z_Revenue\",'Age']\n",
    "    df = df.drop(red_ftrs_1, axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def miss_norm(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Handle missing values then normalize data and return a dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    # List of categorical and numeric features\n",
    "    categ_ftrs_1 = ['Education', 'Marital_Status', 'Kidhome', 'Teenhome', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1', 'AcceptedCmp2', 'Complain', 'Age_Group']\n",
    "\n",
    "    num_ftrs_1 = ['Income', 'Recency', 'MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth', 'Onboard_Days']\n",
    "    \n",
    "    # Drop the target variable\n",
    "    df = df.drop('Response', axis=1)\n",
    "        \n",
    "    num_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('normalize', PowerTransformer(method='yeo-johnson')),\n",
    "    ])\n",
    "    \n",
    "    ct = ColumnTransformer([\n",
    "        ('num_trans', num_transformer, num_ftrs_1),\n",
    "        ('cat_trans', SimpleImputer(strategy='most_frequent'), categ_ftrs_1)\n",
    "    ])\n",
    "        \n",
    "    df = pd.DataFrame(ct.fit_transform(df), \n",
    "                      columns=num_ftrs_1+categ_ftrs_1)\n",
    "        \n",
    "    # Ensure that the final df features are in the right data types\n",
    "    df[categ_ftrs_1] = df[categ_ftrs_1].astype('str')\n",
    "    df[num_ftrs_1] = df[num_ftrs_1].astype('float')\n",
    "     \n",
    "    # Return a dictionary    \n",
    "    return df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_clean_data('data/training_data.csv')\n",
    "df_val = read_clean_data('data/validation_data.csv')\n",
    "\n",
    "target='Response'\n",
    "\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values\n",
    "\n",
    "dict_train = miss_norm(df_train)\n",
    "dict_val = miss_norm(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mgubuntu/anaconda3/envs/marketing_MLOps/lib/python3.9/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    # Define and log parameters\n",
    "    params = {\n",
    "        'min_samples_leaf': 8, \n",
    "        'min_samples_split': 14, \n",
    "        'n_estimators': 90\n",
    "    }\n",
    "    mlflow.log_params(params)\n",
    "    \n",
    "    # Make predictions from pipeline\n",
    "    pipeline = make_pipeline(\n",
    "        DictVectorizer(),\n",
    "        GradientBoostingClassifier(**params, random_state=42)\n",
    "    )\n",
    "    \n",
    "    pipeline.fit(dict_train, y_train)\n",
    "    y_pred = pipeline.predict(dict_val)\n",
    "    \n",
    "    \n",
    "    # Calculate and log the evaluation metrics\n",
    "    metrics = {\n",
    "        'f1': f1_score(y_val, y_pred.round()), \n",
    "        'precision': precision_score(y_val, y_pred.round(), zero_division=0),\n",
    "        'recall': recall_score(y_val, y_pred.round()),\n",
    "        'pr_auc': roc_auc_score(y_val, y_pred.round()),\n",
    "        'accuracy': accuracy_score(y_val, y_pred.round())\n",
    "    }\n",
    "    mlflow.log_metrics(metrics)\n",
    "    \n",
    "    # Log the model and the vectorizer in the pipeline as one\n",
    "    mlflow.sklearn.log_model(pipeline, artifact_path='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    # Define and log parameters\n",
    "    params = {\n",
    "        'min_samples_leaf': 8, \n",
    "        'min_samples_split': 14, \n",
    "        'n_estimators': 90\n",
    "    }\n",
    "    mlflow.log_params(params)\n",
    "    \n",
    "    dv = DictVectorizer()\n",
    "    model = GradientBoostingClassifier(**params, random_state=42)\n",
    "    \n",
    "    X_train = dv.fit_transform(dict_train)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    X_val = dv.transform(dict_val)\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate and log the evaluation metrics\n",
    "    metrics = {\n",
    "        'f1': f1_score(y_val, y_pred.round()), \n",
    "        'precision': precision_score(y_val, y_pred.round(), zero_division=0),\n",
    "        'recall': recall_score(y_val, y_pred.round()),\n",
    "        'pr_auc': roc_auc_score(y_val, y_pred.round()),\n",
    "        'accuracy': accuracy_score(y_val, y_pred.round())\n",
    "    }\n",
    "    mlflow.log_metrics(metrics)\n",
    "    \n",
    "    mlflow.sklearn.log_model(model, artifact_path='model')\n",
    "    \n",
    "    with open('dict_vectorizer.bin', 'wb') as f_out:\n",
    "        pickle.dump(dv, f_out)\n",
    "        \n",
    "    mlflow.log_artifact('dict_vectorizer.bin')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.5172260959943136 minutes\n"
     ]
    }
   ],
   "source": [
    "elapsed_time = (time.time() - start_time)/60\n",
    "print(f\"Execution time: {elapsed_time} minutes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marketing_MLOps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
