{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import os\n",
    "import mlflow\n",
    "import pickle\n",
    "import uuid\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import (f1_score,\n",
    "                             recall_score,\n",
    "                             roc_auc_score,\n",
    "                             accuracy_score, \n",
    "                             precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_clean_data(filename: str) -> pd.DataFrame:\n",
    "    \n",
    "    \"\"\"Read in & clean the data\"\"\"\n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    # Convert 'Kidhome' and 'Teenhome' to categorical\n",
    "    # but first fillna with the most frequent value\n",
    "    dependants = ['Kidhome', 'Teenhome']\n",
    "    df[dependants] = df[dependants].fillna(df[dependants].mode().iloc[0])\n",
    "    df[dependants] = df[dependants].applymap(lambda x: 1 if x > 0 else 0)\n",
    "    \n",
    "    # Conversions into 'datetime' data type\n",
    "    # but first fillna in both variables\n",
    "    df['Year_Birth'] = df['Year_Birth'].fillna(int(df['Year_Birth'].median()))\n",
    "    df['Year_Birth'] = pd.to_datetime(df['Year_Birth'], format='%Y')\n",
    "    \n",
    "    df['Dt_Customer'] = df['Dt_Customer'].fillna(df['Dt_Customer'].mode().iloc[0])\n",
    "    df[\"Dt_Customer\"] = pd.to_datetime(df[\"Dt_Customer\"])\n",
    "    \n",
    "    # Calculate age\n",
    "    # assuming analysis was conducted in 2014 \n",
    "    now = 2014\n",
    "    df['Age'] = now - df['Year_Birth'].dt.year\n",
    "    \n",
    "    # Define the bin edges\n",
    "    bins = [18, 28, 38, 48, 58, 65, np.inf]\n",
    "    # Define the labels for each age group\n",
    "    labels = ['18-27', '28-37', '38-47', '48-57', '58-65', '65+']\n",
    "    # Create age group feature\n",
    "    df['Age_Group'] = pd.cut(df['Age'], bins=bins, labels=labels, right=False)\n",
    "    \n",
    "    # Calculate the number of days since customer enrolled\n",
    "    end_fiscal = datetime(2014, 6, 30)\n",
    "    df['Onboard_Days'] = (end_fiscal - df['Dt_Customer']).dt.days\n",
    "    \n",
    "    # Droping redundant features\n",
    "    red_ftrs_1 = [\"Year_Birth\", \"Dt_Customer\", \"Z_CostContact\", \"Z_Revenue\",'Age']\n",
    "    df = df.drop(red_ftrs_1, axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def miss_norm(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Handle missing values then normalize data and return a dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    # List of categorical and numeric features\n",
    "    categ_ftrs_1 = ['Education', 'Marital_Status', 'Kidhome', 'Teenhome', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1', 'AcceptedCmp2', 'Complain', 'Age_Group']\n",
    "\n",
    "    num_ftrs_1 = ['Income', 'Recency', 'MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth', 'Onboard_Days']\n",
    "    \n",
    "    # Drop the target and the ID variables\n",
    "    df = df.drop(['Response', 'ID'], axis=1)\n",
    "        \n",
    "    num_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('normalize', PowerTransformer(method='yeo-johnson')),\n",
    "    ])\n",
    "    \n",
    "    ct = ColumnTransformer([\n",
    "        ('num_trans', num_transformer, num_ftrs_1),\n",
    "        ('cat_trans', SimpleImputer(strategy='most_frequent'), categ_ftrs_1)\n",
    "    ])\n",
    "        \n",
    "    df = pd.DataFrame(ct.fit_transform(df), \n",
    "                      columns=num_ftrs_1+categ_ftrs_1)\n",
    "        \n",
    "    # Ensure that the final df features are in the right data types\n",
    "    df[categ_ftrs_1] = df[categ_ftrs_1].astype('str')\n",
    "    df[num_ftrs_1] = df[num_ftrs_1].astype('float')\n",
    "    \n",
    "     \n",
    "    # Return a dictionary    \n",
    "    return df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_ID = os.getenv('RUN_ID', '16fb592a742e430a92f6e6a5eee58c45')\n",
    "BASE_LOCATION = 'home/mgubuntu/projects/marketing-mlops/04-deployment/web-service-mlflow/artifacts_local/1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input = 'validation_data'\n",
    "input_file = f'https://raw.githubusercontent.com/Demiga-g/marketing-mlops/main/01-initial-model/data/{data_input}.csv'\n",
    "output_file = f'output/{data_input}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(run_id):\n",
    "    logged_model = f'/{BASE_LOCATION}/{run_id}/artifacts/model'\n",
    "    model = mlflow.pyfunc.load_model(logged_model)\n",
    "    return model\n",
    "    \n",
    "def apply_model(input_file, run_id, output_file):\n",
    "    df = read_clean_data(input_file)\n",
    "    dicts = miss_norm(df)\n",
    "    \n",
    "    model = load_model(run_id)\n",
    "    y_pred = model.predict(dicts)\n",
    "    \n",
    "    df_result = pd.DataFrame()\n",
    "    df_result['CustomerID'] = df['ID']\n",
    "    df_result['ActualResponse'] = df['Response']\n",
    "    df_result['PredictedResponse'] = y_pred\n",
    "    df_result['PredictionStatus'] = (df_result['ActualResponse'] == df_result['PredictedResponse']).map({True: 'Correct', False: 'Incorrect'})\n",
    "    df_result['ModelVersion'] = run_id\n",
    "    \n",
    "    df_result.to_csv(output_file, index=False)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marketing_MLOps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
