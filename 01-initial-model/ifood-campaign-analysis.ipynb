{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Python's version\n",
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import category_encoders as ce\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import (roc_auc_score,\n",
    "                             confusion_matrix,\n",
    "                             classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read training and validation data\n",
    "df_train = pd.read_csv('./data/training_data.csv')\n",
    "df_val = pd.read_csv('./data/validation_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check training data info  \n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check feature diversity\n",
    "df_train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating target variable \n",
    "y_train = df_train['Response']\n",
    "y_val = df_val['Response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of training data to be used later\n",
    "df_train_2 = df_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping redundant features\n",
    "red_ftrs_1 = [\"ID\", \"Dt_Customer\", \"Z_CostContact\", \"Z_Revenue\", \"Response\"]\n",
    "\n",
    "df_train = df_train.drop(red_ftrs_1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating list of categorical features\n",
    "categ_ftrs_1 = list(\n",
    "    df_train.nunique()\n",
    "    [(df_train.nunique() <= 8)]\n",
    "    .index\n",
    ")\n",
    "not_categ = ['TeenHome', 'KidHome']\n",
    "categ_ftrs_1 = [categ for categ in categ_ftrs_1 \n",
    "              if categ not in not_categ]\n",
    "\n",
    "# Creating a list of numerical features\n",
    "num_ftrs_1 = [col for col in df_train.columns \n",
    "            if col not in categ_ftrs_1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "df_train.isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values\n",
    "\n",
    "df_train[num_ftrs_1] = (\n",
    "    df_train[num_ftrs_1].fillna(df_train[num_ftrs_1].median())\n",
    ")\n",
    "\n",
    "df_train[categ_ftrs_1] = (\n",
    "    df_train[categ_ftrs_1].fillna(df_train[categ_ftrs_1].mode().iloc[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at purchases as a whole\n",
    "purchases = list(df_train.filter(regex='Purchases').columns)\n",
    "df_train['total_purchases'] = (\n",
    "    df_train['NumCatalogPurchases'] + df_train['NumDealsPurchases'] + \n",
    "    df_train['NumStorePurchases'] + df_train['NumWebPurchases']\n",
    ")\n",
    "\n",
    "# look at amounts as a whole\n",
    "amount = list(df_train.filter(regex='Mnt').columns)\n",
    "df_train['total_amount'] = (\n",
    "    df_train['MntFishProducts'] + df_train['MntFruits'] + \n",
    "    df_train['MntGoldProds'] + df_train['MntMeatProducts'] + \n",
    "    df_train['MntSweetProducts'] + df_train['MntWines']\n",
    ")\n",
    "\n",
    "# add a dependants feature\n",
    "dependants = list(df_train.filter(regex='home').columns)\n",
    "df_train['dependants'] = df_train['Kidhome'] + df_train['Teenhome']\n",
    "\n",
    "# Drop redundant features\n",
    "red_ftrs_2 = dependants+amount+purchases\n",
    "df_train = df_train.drop(red_ftrs_2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating list of categorical features\n",
    "categ_ftrs_2 = list(\n",
    "    df_train.nunique()\n",
    "    [(df_train.nunique() <= 8)]\n",
    "    .index\n",
    ")\n",
    "\n",
    "categ_ftrs_2 = [categ for categ in categ_ftrs_2\n",
    "              if categ not in ['dependants']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode ordinal categorical variables\n",
    "ordinal_categ = ['Education']\n",
    "categories = ['Basic', '2n Cycle', 'Graduation', 'Master', 'PhD']\n",
    "\n",
    "df_train[ordinal_categ] = pd.Categorical(df_train[ordinal_categ], categories=categories, ordered=True).codes\n",
    "\n",
    "# Encode nominal categorical variables\n",
    "nominal_categs = list(filter(lambda x: x not in ordinal_categ, categ_ftrs_2))\n",
    "\n",
    "df_train[nominal_categs] = (\n",
    "    df_train[nominal_categs].astype('category')\n",
    "    .apply(lambda x: x.cat.codes)\n",
    "    ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Categorical(df_train_2[ordinal_categ], categories=categories, ordered=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_2[ordinal_categ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode ordinal categorical variables\n",
    "ordinal_categ = ['Education']\n",
    "categories = {'Basic':0, '2n Cycle':1, 'Graduation':2, 'Master':3, 'PhD':4}\n",
    "\n",
    "df_train[ordinal_categ] = df_train[ordinal_categ].apply(lambda x: x.map(categories))\n",
    "\n",
    "# Encode nominal categorical variables\n",
    "nominal_categs = list(filter(lambda x: x not in ordinal_categ, categ_ftrs_2))\n",
    "\n",
    "df_train[nominal_categs] = (\n",
    "    df_train[nominal_categs].astype('category')\n",
    "    .apply(lambda x: x.cat.codes)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating a list of numerical features\n",
    "num_ftrs_2 = [col for col in df_train.columns \n",
    "            if col not in categ_ftrs_2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check distribution of numerical features\n",
    "fig, axes = plt.subplots(2, 4, figsize=(8, 4))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, var in enumerate(num_ftrs_2):\n",
    "        sns.histplot(x=var, ax=axes[i], data=df_train, kde=True, )\n",
    "axes[-1].axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    \n",
    "    # Drop redundant features\n",
    "    df = df.drop(red_ftrs_1, axis=1)\n",
    "    \n",
    "    # Handling missing values and transformations\n",
    "    num_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('normalize', MinMaxScaler()),\n",
    "    ])\n",
    "    \n",
    "    ct = ColumnTransformer([\n",
    "        ('num_trans', num_transformer, num_ftrs_1),\n",
    "        ('cat_trans', SimpleImputer(strategy='most_frequent'), \n",
    "         categ_ftrs_1)\n",
    "    ])\n",
    "    \n",
    "    df = pd.DataFrame(ct.fit_transform(df), \n",
    "                      columns=num_ftrs_1+categ_ftrs_1)\n",
    "    \n",
    "    # Compute total purchase\n",
    "    df['total_purchases'] = (\n",
    "        df['NumCatalogPurchases'] + df['NumDealsPurchases'] + \n",
    "        df['NumStorePurchases'] + df['NumWebPurchases']\n",
    "    )\n",
    "    \n",
    "    # Compute total amount\n",
    "    df['total_amount'] = (\n",
    "        df['MntFishProducts'] + df['MntFruits'] + \n",
    "        df['MntGoldProds'] + df['MntMeatProducts'] +\n",
    "        df['MntSweetProducts'] + df['MntWines']\n",
    "    )\n",
    "    \n",
    "    # Add a `dependants` feature\n",
    "    df['dependants'] = df['Kidhome'] + df['Teenhome']\n",
    "    \n",
    "    \n",
    "    # Drop superflous columns\n",
    "    df = df.drop(red_ftrs_2, axis=1)\n",
    "\n",
    "    # Encode ordinal categorical variables\n",
    "    df_train[ordinal_categ] = (\n",
    "        df_train[ordinal_categ]\n",
    "        .apply(lambda x: x.map(categories))\n",
    "    )\n",
    "    \n",
    "    # Encode nominal categorical variables\n",
    "    df[nominal_categs] = (\n",
    "        df[nominal_categs].astype('category')\n",
    "        .apply(lambda x: x.cat.codes)\n",
    "    )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dicts= clean_data(df_train_2).to_dict(orient='records')\n",
    "val_dicts = clean_data(df_val).to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data(df_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = DictVectorizer()\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "X_val = dv.transform(val_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=500)\n",
    "lr.fit(X_train, y_train.values)\n",
    "y_pred = lr.predict(X_train)\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=500)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmat_table(y_true, y_pred):\n",
    "    cmat = confusion_matrix(y_true, y_pred)\n",
    "    cols = pd.MultiIndex.from_tuples(\n",
    "        [('predictions', 0), ('predictions', 1)]\n",
    "    )\n",
    "    indx = pd.MultiIndex.from_tuples(\n",
    "        [('actual', 0), ('actual', 1)]\n",
    "    )\n",
    "    display(pd.DataFrame(cmat, columns=cols, index=indx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmat_table(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_resampled, y_resampled = SMOTE().fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_resampled, y_resampled)\n",
    "y_pred = lr.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmat_table(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_val, lr.decision_function(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_output(X_1, X_2, y_1, y_2, clf):\n",
    "    \n",
    "    # Fit classifier\n",
    "    clf.fit(X_1, y_1)\n",
    "    \n",
    "    # Get prediction\n",
    "    y_pred = clf.predict(X_2)\n",
    "    \n",
    "    # Create confusion matrix table\n",
    "    cols = pd.MultiIndex.from_tuples(\n",
    "        [('predictions', 0), ('predictions', 1)]\n",
    "    )\n",
    "    indx = pd.MultiIndex.from_tuples(\n",
    "        [('actual', 0), ('actual', 1)]\n",
    "    )\n",
    "    cmat = confusion_matrix(y_2, y_pred)\n",
    "    display(pd.DataFrame(cmat, columns=cols, index=indx))\n",
    "    \n",
    "    print('-'*50, '\\n')\n",
    "\n",
    "    # Print classification report\n",
    "    print(classification_report(y_2, y_pred))\n",
    "    \n",
    "    print('-'*50)\n",
    "    \n",
    "    # Get area under curve\n",
    "    auc_score = roc_auc_score(y_2, y_pred)\n",
    "    print(f'area_under_curve: {auc_score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_output(X_resampled, X_val, y_resampled, y_val, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "metrics_output(X_resampled, X_val, y_resampled, y_val, svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(random_state=1)\n",
    "\n",
    "metrics_output(X_resampled, X_val, y_resampled, y_val, rfc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marketing_MLOps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
